{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0hGJwNv0Eof"
   },
   "source": [
    "# **¿De dónde vienen los bebés?** Análisis de la natalidad en Chile\n",
    "\n",
    "## Informe Final\n",
    "\n",
    "Curso CC5205 - Minería de Datos\n",
    "\n",
    "* Claudio Gaete\n",
    "* Joaquín Harcha\n",
    "* Benjamín Ibacache\n",
    "* Matías Vega\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SAQfgnx0Eoh"
   },
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPY0vVq20Eoi"
   },
   "source": [
    "La tasa de fertilidad es una medida que estima la cantidad de hijos que tiene cada mujer durante su vida, en un lugar dado. En 2021, Chile presentaba una tasa de fertilidad de 1.54 [según datos de la ONU](https://ourworldindata.org/grapher/fertility-rate-with-projections?time=earliest..2021&showSelectionOnlyInTable=1&country=~CHL), y actualmente presenta una tasa de 1.3 [según estudios del INE](https://cooperativa.cl/noticias/pais/salud/2023-registro-el-numero-de-nacimientos-mas-bajo-en-la-ultima-decada/2024-01-23/093731.html). Este valor está muy por debajo de la tasa de 2.1 recomendada para que los países desarrollados mantengan estabilidad en cuanto a los grupos etarios de su población, lo cual implica que la población es, en promedio, de una edad cada vez mayor.\n",
    "\n",
    "![Evolución de la tasa de fertilidad en Chile](img/eda/fertilidad.png)\n",
    "\n",
    "Este cambio demográfico puede tener [grandes efectos socioeconómicos](https://www.emol.com/noticias/Nacional/2024/01/23/1119462/chile-2023-efectos-baja-natalidad.html) en el país, por lo cual es necesario estudiar el problema, y considerar medidas que se puedan tomar al respecto. Sin embargo, esto no es tan sencillo como simplemente aumentar la tasa de natalidad, ya que esto puede tener consecuencias inesperadas dependiendo de la manera en la cual se logra. En un ejemplo extremo, prohibir el acceso a anticonceptivos y abortos efectivamente aumenta la tasa de natalidad, pero también puede aumentar la cantidad de muertes de mujeres por abortos ilegales y niños abandonados por sus padres, como [ocurrió en Rumanía](https://www.theguardian.com/news/2014/dec/10/-sp-ceausescus-children) durante la segunda mitad del siglo XX.\n",
    "\n",
    "Luego, para idear estrategias efectivas con las cuales combatir este descenso en la natalidad, primero se debe estudiar de dónde vienen los bebés en Chile: cuáles son las características compartidas por las personas que están teniendo hijos, y cuáles características comparten quienes no los están teniendo. Teniendo esta información, una persona con conocimiento sobre políticas públicas puede hacer un análisis más profundo sobre los posibles motivos de la situación demográfica del país, y posteriormente proponer soluciones que (idealmente) no tengan efectos negativos en la población.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "8K3QasUF0Eoi"
   },
   "source": [
    "## 2. Exploración de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "mxgtvjlc0Eoj"
   },
   "source": [
    "### 2.1. Fuente y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "CFdlvq-p0Eoj"
   },
   "source": [
    "El dataset a partir del cual se explorarán las distintas relaciones entre datos serán los [resultados del último Censo en Chile del 2017](https://www.ine.gob.cl/estadisticas/sociales/censos-de-poblacion-y-vivienda/censo-de-poblacion-y-vivienda). La tabla principal tiene todos sus atributos con identificadores numéricos, por lo cual se tuvo que cruzar con otras tablas para convertir a categóricos los necesarios.\n",
    "\n",
    "Para el estudio de estos datos se tendrán en cuenta aquellas personas identificadas como mujeres entre 16 y 50 años, dejando el total de filas en 4.501.457. Esto se realizó principalmente para reducir el tamaño del set de datos, aunque también es útil para ser consistentes con el cálculo de índices de fertilidad (que considera la cantidad de hijos por mujer en edad fertil).\n",
    "\n",
    "En cuanto a las columnas, se descartaron aquellas que no eran de interés. Esto puede ser tanto por su **redundancia** (como el atributo de sexo, ya que son solamente mujeres) como por ser **demasiado específicas** (como el atributo de comuna de nacimiento). También se agregó la columna de \"Hijo reciente\", que indica si una persona ha tenido hijos recientemente, específicamente en los años 2016 o 2017 (recordando que estos datos son del 2017).\n",
    "\n",
    "Finalmente, se agregaron atributos geográficos numéricos, extraídos de [geodatos abiertos del Censo 2017](https://www.ine.gob.cl/herramientas/portal-de-mapas/geodatos-abiertos). Esto incluye el centroide del distrito en el cual se ubica cada persona (con coordenadas X e Y), y la población, superficie y densidad del distrito. Con esta información agregada, cada fila pasó a tener un total de 25 atributos, incluyendo llaves y la etiqueta. Todo el código de limpieza de datos se encuentra en el [Anexo 1](anexos/1_limpieza.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "i_1JmMZK0Eoj"
   },
   "source": [
    "### 2.2. Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ZrUlmBTA0Eoj"
   },
   "source": [
    "Se presentan los gráficos y tablas finales generadas por el análisis; en el [Anexo 2](anexos/2_eda.ipynb) se incluye el código utilizado para generar las visualizaciones a partir del *DataFrame* con los datos ordenados y filtrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "JeMQiRoc0Eoj"
   },
   "source": [
    "#### 2.2.1. Análisis por edad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "jBaX3Ehg0Eok"
   },
   "source": [
    "La primera intuición que se tiene es que alrededor de los 30 años habrá un máximo en las personas con hijos recientes; esta información se puede corroborar en los histograma y el *boxplot* generados. En cuanto a las personas sin hijos recientes se observa que la distribución está desplazada a mayores edades respecto a las que sí han tenido, siendo también una distribución más uniforme.\n",
    "\n",
    "![Cantidad de personas por edad en el set de datos utilizado](img/eda/edad_bar_total.png) ![Cantidad de personas por edad que han tenido un hijo recientemente](img/eda/edad_bar_hijo_reciente.png)  ![Distribución de edades para mujeres con y sin hijos recientes](img/eda/edad_box.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "HWiO_Yna0Eok"
   },
   "source": [
    "#### 2.2.2. Análisis geográfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "t8RhBq-j0Eok"
   },
   "source": [
    "En la figura inferior se puede observar el porcentaje de mujeres que han tenido un hijo reciente en cada distrito censado. Al comparar esta información con la densidadd de cada distrito, se observa que el porcentaje de mujeres se mantiene relativamente constante, sin importar la densidad del distrito. Se observan algunos *outliers* con muy poca densidad poblacional y gran porcentaje de mujeres con hijo reciente, pero esto se pueden atribuir a distritos muy pequeños, donde los porcentajes podrían variar ampliamente al agregar o quitar una única persona.\n",
    "\n",
    "![Distritos de chile por densidad y porcentaje de mujeres con hijo reciente](img/eda/densidad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "cHifEBrn0Eok"
   },
   "source": [
    "En cuanto al porcentaje de mujeres con hijo reciente según la distribución geográfica de cada distrito, se observa una distribución uniforme a lo largo de las zonas mas pobladas del país. Sin embargo, existen distritos *outliers* con un porcentaje considerablemente distinto al resto, como lo son aquellos cerca de Arica que destacan por ser mayor, o aquellos en el extremo sur de chile donde se ven porcentajes cercanos a 0. No se observa ninguna relación clara entre la superficie del distrito y el porcentaje de mujeres asociado.\n",
    "\n",
    "Observando específicamente la Provincia de Santiago, se ve que todos los distritos son similares entre sí; no hay un distrito que sobresalga por un mayor o menor porcentaje de mujeres con hijo reciente, por lo cual no se pueden hacer asociaciones geográficas, poblacionales o de características socioeconómicas.\n",
    "\n",
    "![Distritos de Chile por porcentaje de mujeres con hijo reciente](img/eda/chile.png) ![Distritos de la Provincia de Santiago por porcentaje de mujeres con hijo reciente](img/eda/santiago.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "mpEz0bFY0Eok"
   },
   "source": [
    "#### 2.2.3. Análisis en varios atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9Xq6MASn0Eol"
   },
   "source": [
    "Al analizar como se relacionan las variables de edad y cantidad de hijos, se observa una concentración de personas con un hijo reciente alrededor de los 33 años cuando ya tenían un hijo anteriormente. Luego se observa otra gran concentración con mujeres de aproximadamente 28 años que ya han tenido 6 o más hijos, lo cual es atribuible a la poca cantidad de gente que cumple estas características. Cabe destacar que el atributo de cantidad de hijos **no** considera al hijo reciente, ya que esto le entregaría información de las etiquetas al modelo.\n",
    "\n",
    "Por otra parte, al mostrar el porcentaje de mujeres con hijos recientes respecto su edad y años de escolaridad, se pueden observar dos grupos con *peaks* alrededor de 20 años de edad con baja escolaridad, y a los 35 años de edad con alta escolaridad.\n",
    "\n",
    "\n",
    "![Edad y total de hijos versus porcentaje de mujeres que han tenido un hijo recientemente](img/eda/edad_hijos.png) ![Edad y escolaridad versus porcentaje de mujeres que han tenido un hijo recientemente](img/eda/edad_escolaridad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tcLk4_fj0Eol"
   },
   "source": [
    "Por último, se pueden analizar los porcentajes de mujeres con hijo reciente versus país/zona de nacimiento y estado de trabajo. Se observa que las mujeres con trabajo remunerado tienden a no tener un hijo recientemente, al tener una diferencia considerable en porcentaje con respecto a las mujeres sin trabajo remunerado. Esto se puede ver en casi todos los países salvo las excepciones de las personas provenientes de Oceanía y Norteamérica. Cabe destacar que las mujeres con licencia médica (por ejemplo, debido al postnatal) sí están consideradas como con trabajo remunerado.\n",
    "\n",
    "![Porcentaje de mujeres con hijo reciente por país/zona y estado de trabajo](img/eda/pais_trabajo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BWdVrDn0Eol"
   },
   "source": [
    "## 3. Preguntas y problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNhgJCqh0Eol"
   },
   "source": [
    "En base a la exploración anterior, se puede observar la dificultad de encontrar características para las personas que tienen (o no) hijos mediante el análisis exploratorio. Sumando a esto la motivación original, surgieron las siguientes preguntas que ayudarán a generar conocimiento respecto a la tendencia a la baja natalidad en Chile.\n",
    "\n",
    "1. ¿Se pueden identificar grupos específicos dentro de la población de personas en Chile que tengan **tasas de natalidad similares**?\n",
    "\n",
    "1. ¿Se puede **predecir la tasa de natalidad** en diferentes regiones del país  basándose en variables como la edad, el nivel educativo, la situación económica, etcétera?\n",
    "\n",
    "1. ¿Qué características de una persona son **más importantes** a la hora de determinar si ha tenido un hijo recientemente o no?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJscDhzh0Eol"
   },
   "source": [
    "## 4. Experimento 1 (clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "YkAyFE7K0Eol"
   },
   "source": [
    "### Propuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4PZ-wxx10Eol"
   },
   "source": [
    "Al querer identificar grupos específicos, se llevará a cabo experimentación mediante ***clustering*** para intentar identificar clases que poseen tasas de natalidad similares.\n",
    "\n",
    "Para esto, primero se identifican las variables que no son relevantes para posteriormente aplicarle algoritmos de clustering al resto. *REGION* es un string y esta información no es procesable, por lo que a cada una de las 16 regiones de Chile se le asignará un número de norte a sur. *PARENTESCO*, *PUEBLO_ORIGINARIO*, *LUGAR_NAC* y  *LUGAR_NAC_PAIS* se descartarán al ser categóricas, y no fácilmente ordenables.\n",
    "\n",
    "Luego se normalizarán las variables numéricas no booleanas, restándoles la media y dividiendo por su desviación estándar. Se encapsularán distintos subconjuntos de atributos para verificar si se evalúan de forma distinta y es posible obtener más información. Con todas las columnas listas se aplicarán los siguientes algoritmos de clustering:\n",
    "\n",
    "* K-Means\n",
    "* Jerárquico (Linkage Complete)\n",
    "* OPTICS (análogo a DBSCAN pero con mejor rendimiento)\n",
    "\n",
    "Para verificar la cantidad óptima de *clusters* en K-Means se utilizará el **método del codo**, y para encontrar un buen valor de `eps` en OPTICS se usará el **método de la rodilla**. Luego se evaluarán los *clusters* obtenidos con cada uno de los algoritmos usando herramientas como el coeficiente de Silhouette y matrices de similitud, para encontrar cuál funciona mejor.\n",
    "\n",
    "Teniendo los *clusters* con mejores métricas, se extraerán muestras de ellos para ver sus características principales. Por último, se verificará la densidad de personas con hijos recientes en estos *clusters* y se compararán para responder la pregunta inicial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TuEQm8a0Eom"
   },
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, es importante mencionar que para los algoritmos Jerárquico y OPTICS se hizo downsampling de la muestra, tomando 40.000 filas de las 4 millones que habían inicialmente; esto se hizo ya que intentar ejecutar los algoritmos con todos los datos producía resultados incoherentes.\n",
    "\n",
    "También se realizó una **reducción de dimensionalidad** a 2 dimensiones, para poder visualizar adecuadamente los clusters creados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para empezar se realizó el método del codo y con un análisis visual se llegó a la conclusión que lo óptimo para K-Means era aplicar el algoritmo con 5 clusters, obteniendo las siguientes visualizaciones:\n",
    "\n",
    "![Método del codo para K-Means](img/cluster/codo.png)\n",
    "![K-Means con 5 clusters](img/cluster/kmeans-5.png)\n",
    "\n",
    "Para K-Means con 5 clusters, se hizo un estudio más en profundidad de cómo se comportan los atributos dentro de cada cluster. Se observa que los clusters se separaron por región geográfica, habiendo un cluster exclusivo para gente de la zona norte, dos para la zona centro y dos para la zona sur. Tanto para la zona centro como sur, uno de sus clusters tiene personas de mayor edad que han tenido más hijos, y el otro tiene personas de menor edad, que han tenido menos hijos. Sin embargo, ningún cluster tiene una proporción significativamente mayor o menor de personas con hijos recientes.\n",
    "\n",
    "En el [Anexo 3](anexos/3_clustering.ipynb) se pueden encontrar gráficos más extensivos sobre la distribución de cada uno de los atributos, mediante *boxplots*.\n",
    "\n",
    "![Heatmap de atributos en 5 clusters K-Means](img/cluster/kmeans_heat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó anteriormente, en lugar de DBSCAN se usó OPTICS, el cual es un algoritmo de funcionamiento análogo a DBSCAN pero más rápido y que entregaba resultados algo mejores. Para obtener un `eps` adecuado se aplicó el metodo de la rodilla, resultando en 0.7. Con esto, se ejecutó el algoritmo utilizando múltiples `min_samples`; la primera figura muestra `min_samples=50`. Lamentablemente, con este valor se obtienen 153 clusters, y al aumentar `min_samples` para que se disminuya la cantidad de clusters, se obtienen clusters de poquísimos elementos en comparación al ruido (como se aprecia en la tercera imagen). Luego, no se logró generar un clustering satisfactorio con OPTICS, por lo cual tampoco se pudo hacer un análisis más profundo.\n",
    "\n",
    "![Método de la rodilla](img/cluster/rodilla.png)\n",
    "![OPTICS min_samples = 50](img/cluster/image.png)\n",
    "![OPTICS min_samples = 100](img/cluster/opticspenca.png)\n",
    "\n",
    "Es interesante notar que OPTICS con `min_samples=50` obtiene un coeficiente de Silhouette de **0.688**. Sin embargo, aunque el coeficiente sea relativamente alto, el hecho de que sean tantos clusters hace que sea infactible analizarlos manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-l7lBUL0I0F"
   },
   "source": [
    "Para el clustering jerárquico, se realizó un dendograma para graficar el complete linkage y así ver una altura adecuada a la cual detener la división de clusters al realizar el algoritmo aglomerativo. Así se llegó a que un valor adecuado para el treshold es 5. Aplicando el algoritmo, se obutiveron las siguientes visualizaciones, donde se observa en la matriz de similitud que no se obtuvieron clusters de particularmente buena calidad. Esto es confirmado por el coeficiente de Silhouette obtenido de **0.281**.\n",
    "\n",
    "![Dendrograma](img/cluster/dendrogram.png)\n",
    "\n",
    "![Clustering jerárquico](img/cluster/jerarquico_matriz.png)\n",
    "\n",
    "Al ser más clusters, es más complicado analizar las características de cada uno que con K-Means; sin embargo, destaca el cluster 8, que corresponde exclusivamente a personas de Isla de Pascua. Al igual que K-Means, hay un fuerte componente geográfico, con clusters de personas del norte y del sur. Para cada zona se presentan clusters de personas con mayor edad, que han tenido más hijos y que tienen menor escolaridad. También se encuentran clusters de personas con las características contrarias (menor edad, menos hijos y mayor escolaridad). Por último, no se observa ningún cluster con una proporción destacable de personas que han tenido un hijo reciente.\n",
    "\n",
    "En el [Anexo 3](anexos/3_clustering.ipynb) se pueden encontrar gráficos más extensivos sobre la distribución de cada uno de los atributos, mediante *boxplots*.\n",
    "\n",
    "![Análisis de atributos de jerárquico](img/cluster/jerarquico_heat.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proporción de hijos recientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se realizaron gráficos de barras mostrando las proporciones de mujeres con un hijo reciente en cada cluster, según K-Means (izquierda) y jerárquico (derecha). Tal y como se había podido deducir del análisis anterior, ninguno de los métodos logra aislar grupos de personas con características comunes, y que además tengan una proporción de hijos recientes que sea significativamente distinta al resto (los clusters con mayor proporción alcanzan tan solo un 9%). Por ende, se puede concluir que la pregunta original tiene una **respuesta negativa**.\n",
    "\n",
    "![Proporcion de hijos recientes en 5 clusters K-Means](img/cluster/kmeans5proporcionhijos.png)\n",
    "![Proporcion de hijos recientes en clustering jerarquico](img/cluster/jerarquicoproporcionhijos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwCPNE4N0Eom"
   },
   "source": [
    "## 5. Experimento 2 (Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WWxNNBV0Eom"
   },
   "source": [
    "### Propuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTnl3qr40Eom"
   },
   "source": [
    "Para ver si es posible predecir la tasa de natalidad, se utilizarán **modelos de Machine Learning** para intentar predecir si una persona con determinadas características ha tenido un hijo recientemente o no.\n",
    "\n",
    "De los 17 atributos de nuestro set de datos, 5 de ellos son datos categóricos en forma de strings, por lo que deben ser convertidos a valores numéricos para ser utilizados en los modelos de clasificación de *scikit-learn*. Esto se realizará mediante *one-hot encoding*.\n",
    "\n",
    "Además, los 8 atributos numéricos que no son binarios serán normalizados. Esto se logrará restando la media y dividiendo por la desviación estándar de cada atributo.\n",
    "\n",
    "\n",
    "\n",
    "Los modelos a comparar serán:\n",
    "\n",
    "* Dummy\n",
    "* Naive Bayes\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Gradient Boosting\n",
    "* Stochastic Gradient Descent\n",
    "\n",
    "Para cada modelo, se utilizará un split 70-30 de entrenamiento-testeo, con el 30% utilizado exclusivamente para la comparación final entre modelos. Para cada modelo, se escogerán hiperparámetros apropiados mediante **grid search** y **5-fold cross-validation** sobre el 70% de datos de entrenamiento, asegurándonos de que el modelo aprenda de subsets de entrenamiento distintos, y que sus hiperparámetros no estén sobre-ajustados a los datos de testing. Para escoger los hiperparámetros de cada modelo, se utilizará principalmente la métrica de F1 calculada sobre la clase positiva (las mujeres que sí tienen un hijo reciente). Esto es para premiar a los modelos que logran predecir con mayor recall y precisión la clase minoritaria, y para que los modelos no puedan obtener mejores puntajes al clasificar todos los elementos como negativos, lo cual sí ocurre al usar F1 promediado sobre todos los elementos (ya sea micro o macro).\n",
    "\n",
    "Es importante destacar que en cada pasada del modelo, se probará hacer **oversampling y undersampling** de la clase minoritaria (personas con hijos recientes) para que exista un balance en los datos de entrenamiento. Esto solo se realizará en los datos de entrenamiento de cada fold; los datos de prueba de cada fold permanecerán intactos, y cuando los datos de entrenamiento pasen a ser (eventualmente) datos de testing, no tendrán ningún tipo de rebalanceo. Esto se implementará mediante *oversamplers*, *undersamplers* y *pipelines* de la librería [**imbalanced-learn**](https://imbalanced-learn.org/stable/index.html).\n",
    "\n",
    "Los hiperparámetros a probar para cada modelo serán los siguientes:\n",
    "\n",
    "* Dummy: no lleva parámetros, se probó sin *undersampling* ni *oversampling* para tener una referencia base.\n",
    "* Decision Tree: se probaron criterios de calidad `gini` y `entropy`, distintas profundidades máximas, y *under/over/sin sampling*.\n",
    "* Naive-Bayes: no lleva parámetros, se probó con *under/over/sin sampling*.\n",
    "* Random Forest: se usaron los mejores parámetros del Decision Tree para la profundidad máxima y el criterio de calidad. Se probaron distintos números de estimadores, y *under/oversampling*.\n",
    "* Gradient Boosting: se usaron los mejores parámetros del Random Forest para la profundidad máxima, el criterio de calidad y el número de estimadores. Se probaron distintos *learning rates*, y *under/oversampling*.\n",
    "* Stochastic Gradient Descent: se probaron distintas funciones de pérdida, y *under/oversampling*.\n",
    "\n",
    "Una vez obtenidos los mejores hiperparámetros para cada modelo, se analizará cada uno utilizando **curvas ROC** y **matrices de confusión**, junto con las métricas estándar (F1, *accuracy*, *recall*). De esta manera, no solo se observará el rendimiento de cada modelo, sino que también la manera en la que logran ese rendimiento, con sus aspectos positivos y negativos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qCAnJ3I0Eom"
   },
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIz5ZSNY0Eom"
   },
   "source": [
    "\n",
    "\n",
    "Haciendo *grid search* y *5-fold cross-validation* sobre cada modelo, con los hiperparámetros indicados anteriormente, se obtuvieron los siguientes resultados:\n",
    "\n",
    "|       Modelo      | Mejores parámetros                           | Mejor F1-score training | F1-score en testing |\n",
    "|:-----------------:|----------------------------------------------|-------------------------|---------------------|\n",
    "|       Dummy       |                       -                      |            -            |         0.06        |\n",
    "|   Decision Tree   | criterion: gini, max-depth: 7, undersampling |           0.22          |         0.20        |\n",
    "|    Naive Bayes    | sin sampling                                 |           0.19          |         0.20        |\n",
    "|   Random Forest   | n_estimators: 100, undersampling             |           0.20          |         0.21        |\n",
    "| Gradient Boosting | learning_rate: 0.25, oversampling            |           0.23          |       **0.25**      |\n",
    "|        SGD        | loss: log_loss, oversampling                 |           0.22          |         0.21        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixwzVaA0Eom"
   },
   "source": [
    "Notamos que todos los experimentos tienen un puntaje F1 similar para la clase positiva, a excepción del Dummy, que es esperado que sea más bajo que el de los demás.\n",
    "\n",
    "Se pueden comparar las métricas obtenidas con el clasificador Dummy (base) versus el clasificador Gradient Boosting. Se escogió este modelo por presentar los mejores resultados, aunque todos presentaban métricas similares. El resto de *classification reports* se pueden observar en el [Anexo 4](anexos/4_machine_learning.ipynb).\n",
    "\n",
    "Se observa que el clasificador Dummy, al etiquetar aleatoriamente en base a la distribución de clases en el set de entrenamiento, clasifica un 94% de muestras como negativas y un 6% como positivas. Como una clase es mucho más prevalente que otra, la etiqueta negativa tiene muy buenas métricas, mientras que la positiva no se identifica correctamente casi nunca.\n",
    "\n",
    "En Gradient Boosting se observa una precisión de 0.15 para la clase positiva; esto indica que hay muchas mujeres sin hijo reciente que están siendo identificadas de manera incorrecta por el algoritmo, lo cual también es demostrado por el *recall* de 0.68 para la clase positiva (peor que el clasificador Dummy). La precisión de 0.98 de la clase negativa muestra que casi ninguna persona con hijo reciente está siendo identificada incorrectamente; esto se complementa con el *recall* relativamente alto de 0.80 para la clase positiva. Se concluye entonces que el modelo de Gradient Boosting está sobreestimando la cantidad de personas que pertenecen a la clase positiva, en desmedro de quienes pertenecen a la clase negativa. AL tener métricas similares, se concluye que los otros modelos están cometiendo los mismos errores.\n",
    "\n",
    "Métricas del clasificador Dummy:\n",
    "\n",
    "|            **Dummy** | **Precision** | **Recall** | **F1-Score** |\n",
    "|---------------------:|:-------------:|:----------:|:------------:|\n",
    "|                    0 |      0.94     |    0.94    |     0.94     |\n",
    "|                    1 |      0.06     |    0.06    |     0.06     |\n",
    "|        Macro Average |      0.56     |    0.74    |     0.53     |\n",
    "|     Weighted Average |      0.93     |    0.69    |     0.77     |\n",
    "|   **Accuracy: 0.88** |               |            |              |\n",
    "\n",
    "Métricas del clasificador Gradient Boosting:\n",
    "\n",
    "|                       | **Precision** | **Recall** | **F1-Score** |\n",
    "|----------------------:|:-------------:|:----------:|:------------:|\n",
    "|                     0 |      0.98     |    0.68    |     0.81     |\n",
    "|                     1 |      0.15     |    0.80    |     0.25     |\n",
    "|         Macro Average |      0.56     |    0.74    |     0.53     |\n",
    "|      Weighted Average |      0.93     |    0.69    |     0.77     |\n",
    "|    **Accuracy: 0.69** |               |            |              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lzbIOd60Eon"
   },
   "source": [
    "En cuanto a los análisis cualitativos, se estudiarán los tres modelos con resultados más relevantes; el resto de gráficos generados se pueden encontrar en el [Anexo 4](anexos/4_machine_learning.ipynb).\n",
    "\n",
    "**Naive Bayes**: este modelo destaca por su capacidad para identificar elementos de la clase positiva, logrando capturar el 83% de los casos reales. Sin embargo, su desempeño al clasificar la clase negativa es muy pobre, teniendo incluso menos de un 50% de éxito.\n",
    "\n",
    "![Curva ROC para Naive Bayes](img/mach/roc_naive.png)\n",
    "![Matriz de confusión para Naive Bayes](img/mach/matrix_naive.png)\n",
    "\n",
    "**SGD** (Stochastic Gradient Descent): el modelo SGD presenta una de las mayores áreas bajo la curva ROC, lo que implica que es uno de los mejores en términos de predicción global. Además, su matriz de confusión muestra una diagonal bien marcada, indicando que el modelo realiza predicciones de manera relativamente precisa.\n",
    "\n",
    "![Curva ROC para SGD](img/mach/roc_sgd.png)\n",
    "![Matriz de confusión para SGD](img/mach/matrix_sgd.png)\n",
    "\n",
    "**Gradient Boosting**: este modelo tiene la mayor área bajo la curva ROC, lo cual sugiere que es el modelo con mayor capacidad discriminativa de todos. También muestra una matriz de confusión con buenas tasas de verdaderos positivos y negativos. No obstante, es importante señalar que, aunque las proporciones de falsos positivos son relativamente bajas para los últimos dos modelos, la predicción correcta de las mujeres que van a tener un hijo reciente seguirá presentando muchos errores. Esto se debe a que solo un 6% de los datos pertenecen a la clase positiva, por lo que el 33% de falsos positivos en la clase negativa es mucho mayor que el 77% de verdaderos positivos sobre la clase positiva. Este desbalanceo de los datos también se refleja en el bajo valor de la métrica de *precision* observado anteriormente.\n",
    "\n",
    "![Curva ROC para Gradient Boosting](img/mach/roc_gboost.png)\n",
    "![Matriz de confusión para Gradient Boosting](img/mach/matrix_gboost.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdFqp2-70Eon"
   },
   "source": [
    "Se puede observar que los modelos entrenados son capaces de clasificar mejor que un modelo aleatorio, por lo cual efectivamente existe alguna correlación entre los atributos utilizados y la etiqueta. Sin embargo, los resultados obtenidos siguen siendo **muy bajos como para poder llegar a predecir** de forma eficiente qué mujeres tendrán un hijo, por lo que la pregunta original tiene una **respuesta negativa**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTZAKDuX0Eon"
   },
   "source": [
    "## 6. Experimento 3 (importancias de atributos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhWxl0_70Eon"
   },
   "source": [
    "### Propuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX-QX4cD0Eon"
   },
   "source": [
    "Se utilizará la herramienta [*permutation feature importances*](https://inria.github.io/scikit-learn-mooc/python_scripts/dev_features_importance.html#feature-importance-by-permutation) para encontrar la importancia de cada atributo según cada uno de los modelos generados en la propuesta anterior. Esta estrategia consiste en permutar las filas de un atributo de manera aleatoria (sin modificar el resto), y en ver cómo este cambio afecta las capacidades predictivas del modelo. Si un atributo es muy importante para determinar la etiqueta, entonces el modelo cometerá más errores cuando el valor del atributo no coincida con la etiqueta adecuada después de la permutación.\n",
    "\n",
    "Al ser aleatorizado, este proceso se debería repetir varias veces para cada modelo, para así obtener un rango de error asociado al valor de las distintas importancias. Obteniendo estas mediciones, se pueden comparar los distintos modelos para ver qué atributos consideran los más importantes, y buscar relaciones con el rendimiento de cada modelo (según lo obtenido en la propuesta 2).\n",
    "\n",
    "Además, las *permutation feature importances* también se pueden comparar con otras maneras de obtener importancias en distintos modelos, para ver si las distintas metodologías llegan a los mismos resultados, e intentar encontrar una explicación si son distintos.\n",
    "\n",
    "* Para modelos basados en árboles de decisión (Decision Tree, Random Forest, Gradient Boosting), existe la propiedad `feature_importances`, que calcula cuánto aumentó la \"pureza\" de los nodos al usar cada uno de los atributos en un *split* del árbol.\n",
    "\n",
    "* Para modelos lineales (SGD), se pueden analizar los coeficientes asociados a cada uno de los atributos.\n",
    "\n",
    "Por último, cabe mencionar que las importancias encontradas por estos modelos dependen también de la capacidad predictiva de ellos, por lo cual es posible que un mejor modelo pueda encontrar relaciones que un peor modelo no sea capaz de comprender. Debido a esto, no hay que tomar los resultados entregados como un *ranking* definitivo de las características que importan, sino que como información a considerar para futuros procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8gYTI3V0Eon"
   },
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9-JZhAX0Eoo"
   },
   "source": [
    "#### Coeficientes de modelos lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZeM3fpF0Eoo"
   },
   "source": [
    "Para SGD (el único modelo lineal probado), se analizaron los coeficientes asociados a cada uno de los atributos. En la figura se muestran los 10 coeficientes con mayor valor absoluto, donde se observan algunos positivos y otros negativos. Es importante que el coeficiente de un atributo muestra la variación de la predicción al cambiar el atributo, si se mantienen **todos los otros atributos fijos**; es decir, no se puede interpretar como la correlación directa entre el atributo y la predicción, ignorando el resto de atributos.\n",
    "\n",
    "Se observa que los atributos que más afectan positivamente al modelo son relaciones de parentesco; si el resto de atributos se mantienen fijos, la predicción del modelo es más positiva cuando el parentesco de la persona con el/la dueño/a de casa es de conviviente, esposa o nuera. Esto tiene sentido, ya que para tener este parentesco la persona probablemente mantiene una relación estable, con lo cual aumentaría la probabilidad de querer tener un hijo.\n",
    "\n",
    "Por otra parte, los atributos que más afectan negativamente son la asistencia a la educación, edad y parentesco de servicio doméstico puertas adentro. En cuanto a la asistencia a la educación, tiene sentido que una persona que está sumergida en el proceso educativo esté menos dispuesta a tener un hijo. También se observó en el análisis exploratorio que las personas con hijos recientes tienden a tener menor edad que las mujeres sin hijos reciente. Y, por último, es de esperar que una persona que trabaje puertas adentro no haya tenido hijos recientemente.\n",
    "\n",
    "Luego, se concluye que el análisis de coeficientes es capaz de mostrar correlaciones importantes entre los atributos, pero nada de lo que no se haya tenido conocimiento (ya sea explícito o implícito) antes de iniciar la experimentación.\n",
    "\n",
    "![Atributos más importantes de SGD (según coeficientes)](img/mach/coef_sgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6eTVtPl0Eoo"
   },
   "source": [
    "#### `feature_importance_` para modelos basados en árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6QM9R2c0Eoo"
   },
   "source": [
    "Para Decision Tree, Random Forest y Gradient Boosting (los tres modelos basados en árboles de decisión que se probaron), se analizaron los resultados de la propiedad `feature_importances_`. En la figura se muestran los 10 atributos más importantes según Gradient Boosting, ya que fue el modelo con mejores resultados entre los tres, y los gráficos de Decision Tree y Random Forest son muy similares (se pueden observar en el [Anexo 5](anexos/5_importancias.ipynb)).\n",
    "\n",
    "Se observa que, con diferencia, el atributo más importante según esta medida es la edad. Esto tiene mucho sentido, ya que es el único atributo para el cual se puede encontrar una correlación clara a simple vista (como se hizo en el análisis exploratorio). También se consideran importantes, aunque en menor medida, los atributos de asistencia actual a la educación, total de hijos, escolaridad y trabajo actual. Estos atributos también fueron analizados previamente en el EDA, por lo cual no se pudo obtener información particularmente novedosa de estos gráficos.\n",
    "\n",
    "![Atributos más importantes de Gradient Boosting (según feature_importance_)](img/mach/tree_gboost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AACWmMOa0Eoo"
   },
   "source": [
    "#### Análisis mediante *permutation feature importances*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7jbsQZN0Eos"
   },
   "source": [
    "Para todos los modelos generados en el experimento 2, se analizaron sus atributos más importantes utilizando la herramienta de *permutation feature importances*. Debido a la naturaleza aleatoria del algoritmo, cada experimento se realizó entre 5 y 10 veces, y se agregaron barras de error mostrando la desviación estándar asociada a cada medición. En las figuras a continuación se muestran los resultados obtenidos para Naive Bayes, Gradient Boosting y SGD, el primero ya que es la única manera de analizar las importancias de este modelo, y los otros dos para comparar con los resultados obtenidos en las figuras anteriores. Los resultados obtenidos para el resto de modelos se encuentran en el [Anexo 5](anexos/5_importancias.ipynb).\n",
    "\n",
    "En los tres casos, se observa que los atributos más importantes son la edad y la asistencia al sistema educativo. Tanto estos como los otros atributos importantes tienden a repetirse en todos los modelos (y en los gráficos previos de análisis usando otros métodos): total de hijos, años de escolaridad, trabajo remunerado y las distintas situaciones de parentesco con el/la dueño/a de casa. También es interesante notar que, aunque el método de *permutation feature importances* sea aleatorizado, no parece haber mucha variación entre los distintos cálculos (ya que las barras de error son muy pequeñas).\n",
    "\n",
    "![Atributos más importantes de Naive Bayes (según permutation)](img/mach/perm_naive.png)\n",
    "![Atributos más importantes de Gradient Boosting (según permutation)](img/mach/perm_gboost.png)\n",
    "![Atributos más importantes de SGD (según permutation)](img/mach/perm_sgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xe3Hwke0Eot"
   },
   "source": [
    "A partir de los resultados obtenidos, se puede concluir que las siguientes características son importantes a la hora de determinar si una mujer tendrá un hijo próximamente o no: **edad, asistencia al sistema educativo, años de escolaridad, total de hijos actuales, estado laboral y parentesco con el/la dueño/a de casa** (que podría interpretarse como estado de relación de pareja). También se puede concluir que características como el país de nacimiento o la ubicación geográfica no influyen particularmente en las decisiones de los modelos.\n",
    "\n",
    "Aunque es interesante haber obtenido esta respuesta a partir de modelos de Machine Learning, todos los atributos mencionados ya habían sido estudiados en el análisis exploratorio, y se había llegado a conclusiones similares, por lo cual no se obtuvo ninguna relación novedosa con este experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qv88XQW0Eot"
   },
   "source": [
    "## 7. Futuras direcciones y conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGftN3Si0Eot"
   },
   "source": [
    "Es claro que los datos del Censo 2017 **no son suficientes** para entender completamente las características y tendencias de las personas que están teniendo hijos en Chile. Por una parte, los modelos de clustering no lograron encontrar muy buenas relaciones entre los datos, y las pocas relaciones que se encontraron lo lograron separar la población adecuadamente entre grupos que tienen hijos y grupos que no. Por otra parte, aunque los modelos de Machine Learning entrenados sí lograron establecer algunas correlaciones entre los atributos y la probabilidad de tener un hijo, no son suficientemente fuertes como para predecir adecuadamente esta probabilidad, y los atributos más importantes encontrados no presentaron información sobre correlaciones que no se hayan encontrado durante el análisis exploratorio.\n",
    "\n",
    "Para quienes deseen replicar este experimento en un futuro, se recomienda lo siguiente:\n",
    "\n",
    "* Probar modelos que podrían generar mejores resultados, o al menos encontrar relaciones más interesantes entre los atributos, pero que el grupo no tuvo el tiempo suficiente como para implementarlos y entrenarlos. Entre estos, destacan KNN y redes neuronales.\n",
    "* Probar los modelos de clustering con varios subconjuntos de atributos distintos.\n",
    "* Si no se tiene mucho tiempo, enfocarse en un algoritmo de clustering y analizarlo a profundidad; no intentar cubrir varios algoritmos de clustering.\n",
    "* Generar nuevos datos, manteniendo preguntas acerca de los atributos que se consideraron más importantes (edad, escolaridad, estado laboral, relación de pareja) y complementar con preguntas sobre atributos nuevos para ver si mejora la capacidad predictiva del modelo. Por ejemplo, se podrían probar preguntas acerca de características socioeconómicas como niveles de ingreso, o preguntas relacionadas a la salud (física y mental).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
